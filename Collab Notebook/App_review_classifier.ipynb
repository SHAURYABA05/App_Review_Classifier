{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Necessary Libraries"
      ],
      "metadata": {
        "id": "rEWkVwZh_sLE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xGId946o_nLD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from collections import Counter\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the data to the data frame"
      ],
      "metadata": {
        "id": "j7QPbrPPAkXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/kaggle/input/kaggle-war-eclipse/test (2).csv')\n",
        "train = pd.read_csv('/kaggle/input/kaggle-war-eclipse/train (1).csv')"
      ],
      "metadata": {
        "id": "5lpMqaSH_z_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "MmgyxcjfAwRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(text):\n",
        "    \"\"\"Custom function to remove punctuation\"\"\"\n",
        "    PUNCT_TO_REMOVE = string.punctuation\n",
        "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))"
      ],
      "metadata": {
        "id": "pnZhUbud_-wI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "    \"\"\"Custom function to remove stopwords\"\"\"\n",
        "    STOPWORDS = set(stopwords.words('english'))\n",
        "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])"
      ],
      "metadata": {
        "id": "x7fEArC7ABVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnt = Counter()\n",
        "for text in train[\"Review\"].values:\n",
        "    for word in text.split():\n",
        "        cnt[word] += 1"
      ],
      "metadata": {
        "id": "u0cDGaMUADxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_rarewords(text):\n",
        "    \"\"\"Custom function to remove rare words\"\"\"\n",
        "    n_rare_words = 10\n",
        "    RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n",
        "    return \" \".join([word for word in str(text).split() if word not in RAREWORDS])"
      ],
      "metadata": {
        "id": "mSJIx75SAFpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stem_words(text):\n",
        "    \"\"\"Custom function to perform stemming\"\"\"\n",
        "    stemmer = PorterStemmer()\n",
        "    return \" \".join([stemmer.stem(word) for word in text.split()])"
      ],
      "metadata": {
        "id": "3TvG_Q1lAHgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_words_str = \"\"\"\n",
        "AFAIK=As Far As I Know\n",
        "AFK=Away From Keyboard\n",
        "ASAP=As Soon As Possible\n",
        "ATK=At The Keyboard\n",
        "ATM=At The Moment\n",
        "A3=Anytime, Anywhere, Anyplace\n",
        "BAK=Back At Keyboard\n",
        "BBL=Be Back Later\n",
        "BBS=Be Back Soon\n",
        "BFN=Bye For Now\n",
        "B4N=Bye For Now\n",
        "BRB=Be Right Back\n",
        "BRT=Be Right There\n",
        "BTW=By The Way\n",
        "B4=Before\n",
        "B4N=Bye For Now\n",
        "CU=See You\n",
        "CUL8R=See You Later\n",
        "CYA=See You\n",
        "FAQ=Frequently Asked Questions\n",
        "FC=Fingers Crossed\n",
        "FWIW=For What It's Worth\n",
        "FYI=For Your Information\n",
        "GAL=Get A Life\n",
        "GG=Good Game\n",
        "GN=Good Night\n",
        "GMTA=Great Minds Think Alike\n",
        "GR8=Great!\n",
        "G9=Genius\n",
        "IC=I See\n",
        "ICQ=I Seek you (also a chat program)\n",
        "ILU=ILU: I Love You\n",
        "IMHO=In My Honest/Humble Opinion\n",
        "IMO=In My Opinion\n",
        "IOW=In Other Words\n",
        "IRL=In Real Life\n",
        "KISS=Keep It Simple, Stupid\n",
        "LDR=Long Distance Relationship\n",
        "LMAO=Laugh My A.. Off\n",
        "LOL=Laughing Out Loud\n",
        "LTNS=Long Time No See\n",
        "L8R=Later\n",
        "MTE=My Thoughts Exactly\n",
        "M8=Mate\n",
        "NRN=No Reply Necessary\n",
        "OIC=Oh I See\n",
        "PITA=Pain In The A..\n",
        "PRT=Party\n",
        "PRW=Parents Are Watching\n",
        "ROFL=Rolling On The Floor Laughing\n",
        "ROFLOL=Rolling On The Floor Laughing Out Loud\n",
        "ROTFLMAO=Rolling On The Floor Laughing My A.. Off\n",
        "SK8=Skate\n",
        "STATS=Your sex and age\n",
        "ASL=Age, Sex, Location\n",
        "THX=Thank You\n",
        "TTFN=Ta-Ta For Now!\n",
        "TTYL=Talk To You Later\n",
        "U=You\n",
        "U2=You Too\n",
        "U4E=Yours For Ever\n",
        "WB=Welcome Back\n",
        "WTF=What The F...\n",
        "WTG=Way To Go!\n",
        "WUF=Where Are You From?\n",
        "W8=Wait...\n",
        "7K=Sick:-D Laugher\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YtzrDNk4AKZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_words_map_dict = {}\n",
        "chat_words_list = []\n",
        "for line in chat_words_str.split(\"\\n\"):\n",
        "    if line != \"\":\n",
        "        cw = line.split(\"=\")[0]\n",
        "        cw_expanded = line.split(\"=\")[1]\n",
        "        chat_words_list.append(cw)\n",
        "        chat_words_map_dict[cw] = cw_expanded\n",
        "chat_words_list = set(chat_words_list)\n",
        "\n",
        "def chat_words_conversion(text):\n",
        "    new_text = []\n",
        "    for w in text.split():\n",
        "        if w.upper() in chat_words_list:\n",
        "            new_text.append(chat_words_map_dict[w.upper()])\n",
        "        else:\n",
        "            new_text.append(w)\n",
        "    return \" \".join(new_text)"
      ],
      "metadata": {
        "id": "RmqDd5ndATVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "UNICODE_EMO = {\n",
        "    u\"\\U0001F600\": \"happy face\",\n",
        "    u\"\\U0001F601\": \"grinning face with smiling eyes\",\n",
        "    u\"\\U0001F602\": \"face with tears of joy\",\n",
        "    u\"\\U0001F603\": \"smiling face with open mouth\",\n",
        "    u\"\\U0001F604\": \"smiling face with open mouth and smiling eyes\",\n",
        "    u\"\\U0001F605\": \"smiling face with open mouth and cold sweat\",\n",
        "    u\"\\U0001F606\": \"smiling face with open mouth and tightly-closed eyes\",\n",
        "    u\"\\U0001F607\": \"smiling face with halo\",\n",
        "    u\"\\U0001F608\": \"smiling face with horns\",\n",
        "    u\"\\U0001F609\": \"winking face\",\n",
        "    u\"\\U0001F60A\": \"smiling face with smiling eyes\",\n",
        "    u\"\\U0001F60B\": \"face savoring delicious food\",\n",
        "    u\"\\U0001F60C\": \"relieved face\",\n",
        "    u\"\\U0001F60D\": \"smiling face with heart-shaped eyes\",\n",
        "    u\"\\U0001F60E\": \"smiling face with sunglasses\",\n",
        "    u\"\\U0001F60F\": \"smirking face\",\n",
        "    u\"\\U0001F610\": \"neutral face\",\n",
        "    u\"\\U0001F611\": \"expressionless face\",\n",
        "    u\"\\U0001F612\": \"unamused face\",\n",
        "    u\"\\U0001F613\": \"face with cold sweat\",\n",
        "    u\"\\U0001F614\": \"pensive face\",\n",
        "    u\"\\U0001F615\": \"confused face\",\n",
        "    u\"\\U0001F616\": \"confounded face\",\n",
        "    u\"\\U0001F617\": \"kissing face\",\n",
        "    u\"\\U0001F618\": \"face throwing a kiss\",\n",
        "    u\"\\U0001F619\": \"kissing face with smiling eyes\",\n",
        "    u\"\\U0001F61A\": \"kissing face with closed eyes\",\n",
        "    u\"\\U0001F61B\": \"face with stuck-out tongue\",\n",
        "    u\"\\U0001F61C\": \"face with stuck-out tongue and winking eye\",\n",
        "    u\"\\U0001F61D\": \"face with stuck-out tongue and tightly-closed eyes\",\n",
        "    u\"\\U0001F61E\": \"disappointed face\",\n",
        "    u\"\\U0001F61F\": \"worried face\",\n",
        "    u\"\\U0001F620\": \"angry face\",\n",
        "    u\"\\U0001F621\": \"pouting face\",\n",
        "    u\"\\U0001F622\": \"crying face\",\n",
        "    u\"\\U0001F623\": \"persevering face\",\n",
        "    u\"\\U0001F624\": \"face with look of triumph\",\n",
        "    u\"\\U0001F625\": \"disappointed but relieved face\",\n",
        "    u\"\\U0001F626\": \"frowning face with open mouth\",\n",
        "    u\"\\U0001F627\": \"anguished face\",\n",
        "    u\"\\U0001F628\": \"fearful face\",\n",
        "    u\"\\U0001F629\": \"weary face\",\n",
        "    u\"\\U0001F62A\": \"sleepy face\",\n",
        "    u\"\\U0001F62B\": \"tired face\",\n",
        "    u\"\\U0001F62C\": \"grimacing face\"\n",
        "}\n",
        "\n",
        "def convert_emojis(text):\n",
        "    for emot in UNICODE_EMO:\n",
        "        text = re.sub(r'('+emot+')', \"_\".join(UNICODE_EMO[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "8BPS6JgyAVsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['Review'] = train['Review'].str.lower()\n",
        "train['Review'] = train['Review'].apply(lambda text: remove_punctuation(text))\n",
        "train['Review'] = train['Review'].apply(lambda text: remove_stopwords(text))"
      ],
      "metadata": {
        "id": "eK5XQRzkAaD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['Review'] = train['Review'].apply(lambda text: remove_rarewords(text))\n",
        "train['Review'] = train['Review'].apply(lambda text: stem_words(text))\n",
        "train['Review'] = train['Review'].apply(convert_emojis)"
      ],
      "metadata": {
        "id": "R4NEZzgtAcXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Training"
      ],
      "metadata": {
        "id": "orjg2bgUA4HA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_data = train['Review']\n",
        "labels = train['Rating']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Model Evaluation\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "wU6j8_4uAgLj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}